{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import shutil\n",
    "import azureml\n",
    "\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Workspace, Run\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.train.dnn import TensorFlow\n",
    "#https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/machine-learning-pipelines/parallel-run/Code/digit_identification.py\n",
    "#https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-parallel-run-step\n",
    "#https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-inferencing-gpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    " \n",
    "svc_pr_password = \"1fY58u0dpP1Yg-i.A~rUp_iz04RxWUFSwv\"\n",
    " \n",
    "svc_pr = ServicePrincipalAuthentication(\n",
    "    tenant_id=\"72f988bf-86f1-41af-91ab-2d7cd011db47\",\n",
    "    service_principal_id=\"8a3ddafe-6dd6-48af-867e-d745232a1833\",\n",
    "    service_principal_password=\"1fY58u0dpP1Yg-i.A~rUp_iz04RxWUFSwv\")\n",
    " \n",
    "ws = Workspace(\n",
    "    subscription_id=\"c46a9435-c957-4e6c-a0f4-b9a597984773\",\n",
    "    resource_group=\"mlops\",\n",
    "    workspace_name=\"gputraining\",\n",
    "    auth=svc_pr\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.datastore import Datastore\n",
    "\n",
    "batchscore_blob = Datastore.register_azure_blob_container(ws, \n",
    "                      datastore_name=\"images_datastore\", \n",
    "                      container_name=\"sampledata\", \n",
    "                      account_name=\"pipelinedata\", \n",
    "                      overwrite=True)\n",
    "\n",
    "def_data_store = ws.get_default_datastore()\n",
    "\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.pipeline.core import PipelineData\n",
    "\n",
    "input_images = Dataset.File.from_files((batchscore_blob, \"batchscoring/images/\"))\n",
    "label_ds = Dataset.File.from_files((batchscore_blob, \"batchscoring/labels/\"))\n",
    "output_dir = PipelineData(name=\"scores\", \n",
    "                          datastore=def_data_store, \n",
    "                          output_path_on_compute=\"batchscoring/results\")\n",
    "\n",
    "input_images = input_images.register(workspace = ws, name = \"input_images\")\n",
    "label_ds = label_ds.register(workspace = ws, name = \"label_ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model(ws, 'tf-dnn-mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='gputraining', subscription_id='c46a9435-c957-4e6c-a0f4-b9a597984773', resource_group='mlops'), name=tf-dnn-mnist, id=tf-dnn-mnist:5, version=5, tags={}, properties={})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml-models/tf-dnn-mnist/5/model\n"
     ]
    }
   ],
   "source": [
    "print(Model.get_model_path('tf-dnn-mnist',5,ws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "compute_name = \"gpucluster1\"\n",
    "\n",
    "# checks to see if compute target already exists in workspace, else create it\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=compute_name)\n",
    "except ComputeTargetException:\n",
    "    config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_NC6\",\n",
    "                                                   vm_priority=\"lowpriority\", \n",
    "                                                   min_nodes=0, \n",
    "                                                   max_nodes=1)\n",
    "\n",
    "    compute_target = ComputeTarget.create(workspace=ws, name=compute_name, provisioning_configuration=config)\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_GPU_IMAGE\n",
    "\n",
    "batch_conda_deps = CondaDependencies.create(pip_packages=[\"tensorflow==1.13.1\", \"pillow\",\n",
    "                                                          \"azureml-core\", \"azureml-dataprep[pandas, fuse]\"])\n",
    "\n",
    "batch_env = Environment(name=\"batch_environment\")\n",
    "batch_env.python.conda_dependencies = batch_conda_deps\n",
    "batch_env.docker.enabled = True\n",
    "batch_env.docker.base_image = DEFAULT_GPU_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_GPU_IMAGE\n",
    "\n",
    "batch_conda_deps = CondaDependencies.create(pip_packages=[\"tensorflow==2.2.0\", \"pillow\",\n",
    "                                                          \"azureml-core\", \"azureml-dataprep[pandas, fuse]\"])\n",
    "\n",
    "batch_env = Environment(name=\"batch_environment\")\n",
    "batch_env.python.conda_dependencies = batch_conda_deps\n",
    "batch_env.docker.enabled = True\n",
    "batch_env.docker.base_image = DEFAULT_GPU_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineParameter\n",
    "from azureml.pipeline.steps import ParallelRunConfig\n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory='.',\n",
    "    entry_script=\"batchscore2.py\",\n",
    "    mini_batch_size=PipelineParameter(name=\"batch_size_param\", default_value=\"5\"),\n",
    "    error_threshold=10,\n",
    "    output_action=\"append_row\",\n",
    "    append_row_file_name=\"mnist_outputs.txt\",\n",
    "    environment=batch_env,\n",
    "    compute_target=compute_target,\n",
    "    process_count_per_node=PipelineParameter(name=\"process_count_param\", default_value=2),\n",
    "    node_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import ParallelRunStep\n",
    "from datetime import datetime\n",
    "\n",
    "parallel_step_name = \"batchscoring-\" + datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "parallelrun_step = ParallelRunStep(\n",
    "    name=parallel_step_name,\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[input_images.as_named_input(\"input_images\")],\n",
    "    output=output_dir,\n",
    "    allow_reuse=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step batchscoring-202007142136 [d47cdd36][51f9eb04-2102-4b1e-aaa9-870bf9d5e801], (This step will run and generate new outputs)\n",
      "Using data reference input_images_0 for StepId [407b198b][347a50ad-d876-4229-99c5-d977e6b60a3c], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted PipelineRun 5849e1d6-2ad0-426d-b1d3-e4a75735648d\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/batch_scoring/runs/5849e1d6-2ad0-426d-b1d3-e4a75735648d?wsid=/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourcegroups/mlops/workspaces/gputraining\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\n",
    "experiment = Experiment(ws, 'batch_scoring')\n",
    "pipeline_run = experiment.submit(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683dfa561f144b54817b5545593b083b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"loading\": true}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 5849e1d6-2ad0-426d-b1d3-e4a75735648d\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/batch_scoring/runs/5849e1d6-2ad0-426d-b1d3-e4a75735648d?wsid=/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourcegroups/mlops/workspaces/gputraining\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 6206bc87-92f2-44bf-a413-2b91c201a6eb\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/batch_scoring/runs/6206bc87-92f2-44bf-a413-2b91c201a6eb?wsid=/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourcegroups/mlops/workspaces/gputraining\n",
      "StepRun( batchscoring-202007142136 ) Status: NotStarted\n",
      "StepRun( batchscoring-202007142136 ) Status: Running\n"
     ]
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(pipeline_run).show()\n",
    "\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_on_datastore = mnist_blob.path('mnist/0.png')\n",
    "single_image_ds = Dataset.File.from_files(path=path_on_datastore, validate=False)\n",
    "\n",
    "pipeline_run_2 = experiment.submit(pipeline, \n",
    "                                   pipeline_parameters={\"mnist_param\": single_image_ds, \n",
    "                                                        \"batch_size_param\": \"1\",\n",
    "                                                        \"process_count_param\": 1}\n",
    ")\n",
    "\n",
    "pipeline_run_2.wait_for_completion(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
